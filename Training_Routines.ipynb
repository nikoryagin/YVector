{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Downloading code and dataset"
      ],
      "metadata": {
        "id": "A9zgodOGNRo1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSgSu_JxY67c",
        "outputId": "d5e34054-faa9-4119-e916-40565f92bc4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'YVector'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 10 (delta 2), reused 10 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (10/10), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/nikoryagin/YVector.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5J-R7YuyD_u",
        "outputId": "3a3d9632-7a2c-4c10-c9d4-ef93ad0b61b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/YVector\n"
          ]
        }
      ],
      "source": [
        "%cd YVector\n",
        "#!mkdir dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "WimSJuFbMzzK",
        "outputId": "3f3c3cf9-a069-4bd1-bc94-5ddc39e1b7df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-04-03 15:15:17--  https://www.openslr.org/resources/12/train-clean-100.tar.gz\n",
            "Resolving www.openslr.org (www.openslr.org)... 46.101.158.64\n",
            "Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: http://us.openslr.org/resources/12/train-clean-100.tar.gz [following]\n",
            "--2022-04-03 15:15:17--  http://us.openslr.org/resources/12/train-clean-100.tar.gz\n",
            "Resolving us.openslr.org (us.openslr.org)... 46.101.158.64\n",
            "Connecting to us.openslr.org (us.openslr.org)|46.101.158.64|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6387309499 (5.9G) [application/x-gzip]\n",
            "Saving to: ‘train-clean-100.tar.gz’\n",
            "\n",
            "train-clean-100.tar 100%[===================>]   5.95G  20.9MB/s    in 4m 56s  \n",
            "\n",
            "2022-04-03 15:20:14 (20.6 MB/s) - ‘train-clean-100.tar.gz’ saved [6387309499/6387309499]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.openslr.org/resources/12/train-clean-100.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing dataset"
      ],
      "metadata": {
        "id": "VGbDRjoGNgu5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VTp-saxHmIg"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "files = Path('/content/YVector/dataset/LibriSpeech/train-clean-100').glob('*')\n",
        "wrong_to_correct = {}\n",
        "for i, file in enumerate(files):\n",
        "    wrong_to_correct[int(file.name)] = i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pohp6s3-8WGn"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "\n",
        "class RandomClip:\n",
        "    def __init__(self, clip_length):\n",
        "        self.clip_length = int(clip_length)\n",
        "\n",
        "    def __call__(self, item):\n",
        "        item[0] = item[0].squeeze()\n",
        "        audio_length = item[0].shape[0]\n",
        "        if audio_length < self.clip_length:\n",
        "            item[0] = torch.nn.functional.pad(item[0], (self.clip_length // 2, self.clip_length // 2))\n",
        "        audio_length = item[0].shape[0]\n",
        "\n",
        "        offset = random.randint(0, audio_length-self.clip_length)\n",
        "\n",
        "        item[0] = item[0][offset:(offset+self.clip_length)]\n",
        "        item[0] = item[0].unsqueeze(0)\n",
        "        item[0] = item[0].unsqueeze(0)\n",
        "        return item\n",
        "\n",
        "class Normalize:\n",
        "    def __call__(self, item):\n",
        "        item[0] = item[0].squeeze()\n",
        "        item[0] = item[0] / torch.max(item[0] + 0.000001)\n",
        "        item[0] = item[0].unsqueeze(0)\n",
        "        item[0] = item[0].unsqueeze(0)\n",
        "        return item\n",
        "\n",
        "\n",
        "def collate_fn(data):\n",
        "    for i in range(len(data)):\n",
        "        data[i] = tuple(RandomClip(16000*3.9)(list(data[i])))\n",
        "        data[i] = tuple(Normalize()(list(data[i])))\n",
        "        if i == 0:\n",
        "          batch_wave = data[i][0]\n",
        "          batch_labels = torch.tensor(wrong_to_correct[data[i][3]]).unsqueeze(0)\n",
        "\n",
        "        else:\n",
        "          batch_wave = torch.cat((batch_wave, data[i][0]), dim = 0)\n",
        "          batch_labels = torch.cat((batch_labels, torch.tensor(wrong_to_correct[data[i][3]]).unsqueeze(0)), dim = 0)\n",
        "\n",
        "\n",
        "    return batch_wave, batch_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTg-p9BWyAO9",
        "outputId": "78c265f8-20d9-4ea4-b1a0-2e3f1ef80bdf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "import torchaudio\n",
        "libri_train = torchaudio.datasets.LIBRISPEECH(root='dataset', download=False)\n",
        "dataloader = torch.utils.data.DataLoader(libri_train,\n",
        "                                          batch_size=32,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=4,\n",
        "                                          collate_fn = collate_fn,\n",
        "                                          pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up training process"
      ],
      "metadata": {
        "id": "SSZnAqbUNvxf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9EI7RS9yx8Em"
      },
      "outputs": [],
      "source": [
        "from yvector import YVectorModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3Q_gRaVF4Rd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# from https://github.com/Leethony/Additive-Margin-Softmax-Loss-Pytorch\n",
        "class AdMSoftmaxLoss(nn.Module):\n",
        "\n",
        "    def __init__(self, in_features, out_features, s=30.0, m=0.4):\n",
        "        '''\n",
        "        AM Softmax Loss\n",
        "        '''\n",
        "        super(AdMSoftmaxLoss, self).__init__()\n",
        "        self.s = s\n",
        "        self.m = m\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.fc = nn.Linear(in_features, out_features, bias=False)\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        '''\n",
        "        input shape (N, in_features)\n",
        "        '''\n",
        "        assert len(x) == len(labels)\n",
        "        assert torch.min(labels) >= 0\n",
        "        assert torch.max(labels) < self.out_features\n",
        "        \n",
        "        for W in self.fc.parameters():\n",
        "            W = F.normalize(W, dim=1)\n",
        "\n",
        "        x = F.normalize(x, dim=1)\n",
        "\n",
        "        wf = self.fc(x)\n",
        "        numerator = self.s * (torch.diagonal(wf.transpose(0, 1)[labels]) - self.m)\n",
        "        excl = torch.cat([torch.cat((wf[i, :y], wf[i, y+1:])).unsqueeze(0) for i, y in enumerate(labels)], dim=0)\n",
        "        denominator = torch.exp(numerator) + torch.sum(torch.exp(self.s * excl), dim=1)\n",
        "        L = numerator - torch.log(denominator)\n",
        "        return -torch.mean(L)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2yg9itSGaty"
      },
      "outputs": [],
      "source": [
        "in_features = 512\n",
        "out_features = 251 # Number of classes\n",
        "\n",
        "criterion = AdMSoftmaxLoss(in_features, out_features, s=30.0, m=0.35).to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MazU1JezMQul"
      },
      "outputs": [],
      "source": [
        "model = YVectorModel().to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZOjHGe5JGlf"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), 0.01, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzW9xpOPz_ve",
        "outputId": "a1c1534f-0bfc-47d5-b609-e2118ce9baa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "MZCd2RHOOPa2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "I5eRpQSxQWpI"
      },
      "outputs": [],
      "source": [
        "n_epoch = 60\n",
        "min_loss = 2.9\n",
        "for i in range(n_epoch):\n",
        "  j = 1\n",
        "  cum_loss = 0\n",
        "  for X, y in dataloader:\n",
        "      optimizer.zero_grad()\n",
        "      X, y = X.to('cuda'), y.to('cuda')\n",
        "      embeds = model(X)\n",
        "      loss = criterion(embeds, y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      with torch.no_grad():\n",
        "        j += 1\n",
        "        cum_loss += loss\n",
        "        if j % 100 == 0:\n",
        "          if cum_loss / 100 < min_loss:\n",
        "            min_loss = cum_loss / 100\n",
        "            torch.save({\n",
        "            'epoch': i,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, '/content/drive/MyDrive/vk/vk{}.pth'.format(i))\n",
        "          print(cum_loss / 100)\n",
        "          cum_loss = 0"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "A9zgodOGNRo1",
        "VGbDRjoGNgu5"
      ],
      "name": "Training Routines.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}